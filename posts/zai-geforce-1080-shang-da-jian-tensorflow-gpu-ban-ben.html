<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="zh_cn">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>在 Geforce 1080 上搭建 TensorFlow GPU 版本 | 赵骥's Site</title>
<link href="../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../rss.xml">
<link rel="canonical" href="https://qiwulun.github.io/posts/zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html">
<!--[if lt IE 9]><script src="../assets/js/html5.js"></script><![endif]--><link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
<link href="../mycss/tweak.css" rel="stylesheet" type="text/css">
<base target="_parent">
<meta name="author" content="Zhao JI">
<link rel="prev" href="cong-xue-sheng-dao-zhi-chang.html" title="从学生到职场" type="text/html">
<link rel="next" href="git-shi-yong-ji-qiao.html" title="git 使用技巧" type="text/html">
<meta property="og:site_name" content="赵骥's Site">
<meta property="og:title" content="在 Geforce 1080 上搭建 TensorFlow GPU 版本">
<meta property="og:url" content="https://qiwulun.github.io/posts/zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html">
<meta property="og:description" content="Table of Contents


安装 TensorFlow

CPU 版

Demo


GPU 版
tensorlayer 把API进行了一些包装


linux

安装 Anaconda
安装显卡驱动
安装 cuda toolbox

测试


安装 cuDNN
从源文件安装 TensorFlow

Clone the TensorFlow repository
安装 Bazel
py">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2016-11-10T17:39:02+08:00">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">跳到主内容</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://qiwulun.github.io/">

                <span id="blog-title">赵骥's Site</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="../archive.html">文章存档</a>
                </li>
<li>
<a href="../galleries/">图库</a>
                </li>
<li>
<a href="../categories/">标签</a>
                </li>
<li>
<a href="../rss.xml">RSS 源</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="#" class="u-url">在 Geforce 1080 上搭建 TensorFlow GPU 版本</a></h1>

        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">
                    Zhao JI
            </span></p>
            <p class="dateline"><a href="#" rel="bookmark"><time class="published dt-published" datetime="2016-11-10T17:39:02+08:00" itemprop="datePublished" title="2016-11-10 17:39">2016-11-10 17:39</time></a></p>
            

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li>
<a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-1">安装 TensorFlow</a>
<ul>
<li>
<a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-1-1">CPU 版</a>
<ul>
<li><a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-1-1-1">Demo</a></li>
</ul>
</li>
<li><a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-1-2">GPU 版</a></li>
<li><a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-1-3">tensorlayer 把API进行了一些包装</a></li>
</ul>
</li>
<li>
<a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-2">linux</a>
<ul>
<li><a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-2-1">安装 Anaconda</a></li>
<li><a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-2-2">安装显卡驱动</a></li>
<li>
<a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-2-3">安装 cuda toolbox</a>
<ul>
<li><a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-2-3-1">测试</a></li>
</ul>
</li>
<li><a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-2-4">安装 cuDNN</a></li>
<li>
<a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-2-5">从源文件安装 TensorFlow</a>
<ul>
<li><a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-2-5-1">Clone the TensorFlow repository</a></li>
<li><a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-2-5-2">安装 Bazel</a></li>
<li><a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-2-5-3">python 的依赖</a></li>
<li><a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-2-5-4">编译安装TensorFlow:</a></li>
</ul>
</li>
</ul>
</li>
<li>
<a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-3">修补图像</a>
<ul>
<li><a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-3-1">OpenFace Docker</a></li>
</ul>
</li>
<li>
<a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-4">基本知识</a>
<ul>
<li><a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-4-1">变量与运算 Variables and ops</a></li>
<li>
<a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-4-2">两种作用域：变量作用域 variable<sub>scope</sub> 与命名作用域 name<sub>scope</sub></a>
<ul>
<li><a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-4-2-1">变量作用域目标是为了影响变量 variable ，对于其它的运算 op 同样也会影响</a></li>
<li><a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-4-2-2">而 name<sub>scope</sub> 不一定改变 Variable 的名字</a></li>
<li><a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-4-2-3">两者的核心区别： tf.get<sub>variable，</sub> 用于共享变量</a></li>
<li><a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-4-2-4">切换方法</a></li>
</ul>
</li>
</ul>
</li>
<li>
<a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-5">版本</a>
<ul>
<li><a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-5-1">Batch Norm 巨慢</a></li>
</ul>
</li>
</ul>
</div>
</div>
<hr>
<!-- TEASER_END --><div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">安装 TensorFlow</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-sec-1-1" class="outline-3">
<h3 id="sec-1-1">CPU 版</h3>
<div class="outline-text-3" id="text-1-1">
<p>
先开一个虚拟环境
</p>
<div class="highlight"><pre><span></span>conda create --name tensorflow python=2.7
source activate tensorflow
</pre></div>

<p>
安装必要的库
</p>
<div class="highlight"><pre><span></span>conda install numpy scipy
</pre></div>

<p>
pip 安装 
</p>

<div class="highlight"><pre><span></span># Ubuntu/Linux 64-bit
$ sudo apt-get install python-pip python-dev
# Ubuntu/Linux 64-bit, CPU only, Python 2.7
$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl
sudo pip install --upgrade $TF_BINARY_URL
</pre></div>
</div>
<div id="outline-container-sec-1-1-1" class="outline-4">
<h4 id="sec-1-1-1">Demo</h4>
</div>
</div>
<div id="outline-container-sec-1-2" class="outline-3">
<h3 id="sec-1-2">GPU 版</h3>
<div class="outline-text-3" id="text-1-2">
<p>
默认是 CUDA 8.0 和CUDNN 4.5 ，不支持 1080
</p>
</div>
</div>
<div id="outline-container-sec-1-3" class="outline-3">
<h3 id="sec-1-3">tensorlayer 把API进行了一些包装</h3>
<div class="outline-text-3" id="text-1-3">
<div class="highlight"><pre><span></span>pip install git+https://github.com/zsdonghao/tensorlayer.git
</pre></div>
</div>
</div>
</div>
<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2">linux</h2>
<div class="outline-text-2" id="text-2">
<p>
<a href="http://www.52nlp.cn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%BB%E6%9C%BA%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE-ubuntu-16-04-nvidia-gtx-1080-cuda-8">http://www.52nlp.cn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%BB%E6%9C%BA%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE-ubuntu-16-04-nvidia-gtx-1080-cuda-8</a>
</p>

<p>
<a href="http://www.52nlp.cn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%BB%E6%9C%BA%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE-ubuntu16-04-geforce-gtx1080-tensorflow">http://www.52nlp.cn/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%BB%E6%9C%BA%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE-ubuntu16-04-geforce-gtx1080-tensorflow</a>
</p>

<p>
<a href="http://blog.csdn.net/hjimce/article/details/51999566">http://blog.csdn.net/hjimce/article/details/51999566</a>
</p>
<pre class="example">
cuda8.0+ubuntu16.04+theano、caffe、tensorflow环境搭建

目前自己撘过深度学习各种库、各种环境，已经搭建了n多台电脑，发现每台电脑配置安装方法各不相同，总会出现各不相同的错误，真是心塞。笔记本和台式机有差别，台式机之间的安装方法又各不相同，不同的系统版本环境、平台又各有差异。比如昨天搞的一台电脑，可能因为显卡比较新，然而ubuntu14.04、ubuntu15.04都比较旧，连安装系统都装不上，一开始在14.04上重装了n多次系统，还以为是自己电脑的问题。最后在ubuntu16.04竟然非常顺利完成了安装；然而16.04的版本，只有cuda8.0才支持，在这台破电脑上，又折腾了我快一天的时间。

显卡：GTX960

环境：ubuntu16.04、cuda8.0

下面是我的安装之路，总的来说theano、keras、tensorflow都比较容易安装；最难安装的是caffe，因为caffe调用的第三方库比较杂、比较多。
</pre>
</div>

<div id="outline-container-sec-2-1" class="outline-3">
<h3 id="sec-2-1">安装 Anaconda</h3>
<div class="outline-text-3" id="text-2-1">
<p>
bash Anaconda3-4.1.1-Linux-x86<sub>64</sub>.sh
</p>
</div>
</div>
<div id="outline-container-sec-2-2" class="outline-3">
<h3 id="sec-2-2">安装显卡驱动</h3>
<div class="outline-text-3" id="text-2-2">
<p>
会说 X－server 没有关闭
</p>
<ul class="org-ul">
<li>切换到单用户模式 CTL+ALT+F1进入
<ul class="org-ul">
<li>如果要是没有文字，那很有可能是显卡驱动的问题（看，我要装个显卡就这么难）
<ol class="org-ol">
<li>
<code>sudo apt install bumblebee bumblebee-nvidia primus linux-headers-generic</code>
</li>
<li>然后重启
</li>
</ol>
</li>
</ul>
</li>
<li>关闭 lightdm <code>sudo service lightdm stop</code>
</li>
<li>再执行安装，就可以了。
<ul class="org-ul">
<li>sudo sh NVIDIA-Linux-x86<sub>64</sub>-367.36.run
</li>
</ul>
</li>
</ul>
<ul class="org-ul">
<li>但是桌面却少了工具栏和任务栏，几经周折，找到了解决方法如下：
<ul class="org-ul">
<li>就是要重新安装ubuntu desktop：
<ul class="org-ul">
<li>命令1：
<ul class="org-ul">
<li>
<code>rm -rf ~/.compiz* ~/.config/compiz* ~/.cache/compiz* ~/.gconf/apps/compiz* ~/.config/dconf ~/.cache/dconf ~/.cache/unity</code>
</li>
<li>
<code>sudo apt remove ubuntu-desktop</code>
</li>
</ul>
</li>
<li>命令2：
<ul class="org-ul">
<li>
<code>sudo apt install ubuntu-desktop</code>
</li>
</ul>
</li>
<li>命令3：（Ctrl Alt F1 ,然后重启桌面）
<ul class="org-ul">
<li>
<code>sudo service lightdm stop</code>
</li>
<li>
<code>sudo service lightdm start</code>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-2-3" class="outline-3">
<h3 id="sec-2-3">安装 cuda toolbox</h3>
<div class="outline-text-3" id="text-2-3">
<ul class="org-ul">
<li>不要用 cuda 8.0 自带的那个驱动，有的是坑，要用上面的 367.36
</li>
<li>GCC 的版本太高 Ubuntu 16.04 里面是 GCC 5.4 要降级到 4.9
</li>
</ul>
<div class="highlight"><pre><span></span>sudo apt-get install g++-4.9
sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.9 20
sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-5 10
sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-4.9 20
sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-5 10
sudo update-alternatives --install /usr/bin/cc cc /usr/bin/gcc 30
sudo update-alternatives --set cc /usr/bin/gcc
sudo update-alternatives --install /usr/bin/c++ c++ /usr/bin/g++ 30
sudo update-alternatives --set c++ /usr/bin/g++
</pre></div>
<ul class="org-ul">
<li>安装 cuda toolbox
<ul class="org-ul">
<li>sudo sh cuda<sub>8</sub>.0.27<sub>linux</sub>.run
</li>
<li>sudo sh cuda<sub>8</sub>.0.27.1<sub>linux</sub>.run 
</li>
</ul>
</li>
<li>安装完毕后，再声明一下环境变量，并将其写入到 ~/.bashrc 的尾部:
</li>
</ul>
<div class="highlight"><pre><span></span>export PATH=/usr/local/cuda-8.0/bin${PATH:+:${PATH}}
export LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
</pre></div>
</div>
<div id="outline-container-sec-2-3-1" class="outline-4">
<h4 id="sec-2-3-1">测试</h4>
<div class="outline-text-4" id="text-2-3-1">
<p>
最后再来测试一下CUDA，运行：
</p>
</div>
<ul class="org-ul">
<li>
<a id="sec-2-3-1-1" name="sec-2-3-1-1"></a><code>nvidia-smi</code><br>
</li>
<li>
<a id="sec-2-3-1-2" name="sec-2-3-1-2"></a>再来试几个CUDA例子：<br><div class="outline-text-5" id="text-2-3-1-2">
<div class="highlight"><pre><span></span>cd 1_Utilities/deviceQuery
make
</pre></div>
<p>
这里如果提示gcc版本过高，可以安装低版本的gcc并做软连接替换，具体方法请自行google，我用低版本的gcc4.9替换了ubuntu16.04自带的gcc5.x版本。
</p>

<p>
执行 ./deviceQuery ，得到:
</p>


<pre class="example">
./deviceQuery Starting…

CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 1 CUDA Capable device(s)

Device 0: “GeForce GTX 1080”
CUDA Driver Version / Runtime Version 8.0 / 8.0
CUDA Capability Major/Minor version number: 6.1
Total amount of global memory: 8112 MBytes (8506179584 bytes)
(20) Multiprocessors, (128) CUDA Cores/MP: 2560 CUDA Cores
GPU Max Clock rate: 1835 MHz (1.84 GHz)
Memory Clock rate: 5005 Mhz
Memory Bus Width: 256-bit
L2 Cache Size: 2097152 bytes
Maximum Texture Dimension Size (x,y,z) 1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)
Maximum Layered 1D Texture Size, (num) layers 1D=(32768), 2048 layers
Maximum Layered 2D Texture Size, (num) layers 2D=(32768, 32768), 2048 layers
Total amount of constant memory: 65536 bytes
Total amount of shared memory per block: 49152 bytes
Total number of registers available per block: 65536
Warp size: 32
Maximum number of threads per multiprocessor: 2048
Maximum number of threads per block: 1024
Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
Max dimension size of a grid size (x,y,z): (2147483647, 65535, 65535)
Maximum memory pitch: 2147483647 bytes
Texture alignment: 512 bytes
Concurrent copy and kernel execution: Yes with 2 copy engine(s)
Run time limit on kernels: Yes
Integrated GPU sharing Host Memory: No
Support host page-locked memory mapping: Yes
Alignment requirement for Surfaces: Yes
Device has ECC support: Disabled
Device supports Unified Addressing (UVA): Yes
Device PCI Domain ID / Bus ID / location ID: 0 / 1 / 0
Compute Mode:
&lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;

deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GTX 1080
Result = PASS
</pre>
</div>
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-2-4" class="outline-3">
<h3 id="sec-2-4">安装 cuDNN</h3>
<div class="outline-text-3" id="text-2-4">
<div class="highlight"><pre><span></span>tar -zxvf cudnn-8.0-linux-x64-v5.0-ga.tgz
</pre></div>

<p>
cuda/include/cudnn.h
cuda/lib64/libcudnn.so
cuda/lib64/libcudnn.so.5
cuda/lib64/libcudnn.so.5.0.5
cuda/lib64/libcudnn<sub>static</sub>.a
</p>

<div class="highlight"><pre><span></span>sudo cp cuda/include/cudnn.h /usr/local/cuda/include/
sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64/
sudo chmod a+r /usr/local/cuda/include/cudnn.h
sudo chmod a+r /usr/local/cuda/lib64/libcudnn*
</pre></div>
</div>
</div>
<div id="outline-container-sec-2-5" class="outline-3">
<h3 id="sec-2-5">从源文件安装 TensorFlow</h3>
<div class="outline-text-3" id="text-2-5">
</div>
<div id="outline-container-sec-2-5-1" class="outline-4">
<h4 id="sec-2-5-1">Clone the TensorFlow repository</h4>
<div class="outline-text-4" id="text-2-5-1">
<p>
$ git clone <a href="https://github.com/tensorflow/tensorflow">https://github.com/tensorflow/tensorflow</a>
</p>
</div>
</div>
<div id="outline-container-sec-2-5-2" class="outline-4">
<h4 id="sec-2-5-2">安装 Bazel</h4>
<div class="outline-text-4" id="text-2-5-2">
</div>
<ul class="org-ul">
<li>
<a id="sec-2-5-2-1" name="sec-2-5-2-1"></a>1、先装jdk<br><div class="outline-text-5" id="text-2-5-2-1">
<p>
bazel需要Java JDK 8，在ubuntu16.04直接apt-get安装即可：
</p>
<div class="highlight"><pre><span></span>sudo apt-get update  
# sudo apt-get install default-jre  
sudo apt-get install openjdk-8-jre  
# sudo apt-get install default-jdk  
sudo apt-get install openjdk-8-jdk  

sudo update-alternatives --config java
sudo update-alternatives --config javac
# 选择8的那个
</pre></div>
</div>
</li>
<li>
<a id="sec-2-5-2-2" name="sec-2-5-2-2"></a>2、安装编译工具Bazel<br><div class="outline-text-5" id="text-2-5-2-2">
<p>
<a href="http://www.bazel.io/docs/install.html#ubuntu">http://www.bazel.io/docs/install.html#ubuntu</a>
</p>

<div class="highlight"><pre><span></span># 从Bazel github上最新的Linux relase版本：
wget https://github.com/bazelbuild/bazel/releases/download/0.3.0/bazel-0.3.0-installer-linux-x86_64.sh

# 下载完毕后执行：
chmod +x bazel-0.3.0-installer-linux-x86_64.sh
./bazel-0.3.0-installer-linux-x86_64.sh --user
</pre></div>


<p>
然后在 ~/.bashrc中追加：
</p>
<div class="highlight"><pre><span></span>source /home/zhaoji/.bazel/bin/bazel-complete.bash
export PATH=$PATH:/home/zhaoji/.bazel/bin
</pre></div>
</div>
</li>
</ul>
</div>
<div id="outline-container-sec-2-5-3" class="outline-4">
<h4 id="sec-2-5-3">python 的依赖</h4>
<div class="outline-text-4" id="text-2-5-3">
<div class="highlight"><pre><span></span># For Python 2.7:
$ sudo apt-get install python-numpy swig python-dev python-wheel
# For Python 3.x:
$ sudo apt-get install python3-numpy swig python3-dev python3-wheel
</pre></div>
</div>
</div>
<div id="outline-container-sec-2-5-4" class="outline-4">
<h4 id="sec-2-5-4">编译安装TensorFlow:</h4>
<div class="outline-text-4" id="text-2-5-4">
</div>
<ul class="org-ul">
<li>
<a id="sec-2-5-4-1" name="sec-2-5-4-1"></a>首先从github上克隆TensorFlow最新的代码：<br><div class="outline-text-5" id="text-2-5-4-1">
<p>
<code>git clone https://github.com/tensorflow/tensorflow -b v0.10</code>
</p>
</div>
</li>
<li>
<a id="sec-2-5-4-2" name="sec-2-5-4-2"></a>代码下载完毕之后，进入tensorflow主目录，执行：<br><div class="outline-text-5" id="text-2-5-4-2">
<p>
<code>./configure</code>
</p>
</div>
</li>
<li>
<a id="sec-2-5-4-3" name="sec-2-5-4-3"></a>Google云平台的支持<br><div class="outline-text-5" id="text-2-5-4-3">
<p>
Please specify the location of python. [Default is /usr/bin/python]:
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] y
Google Cloud Platform support will be enabled for TensorFlow
</p>

<p>
ERROR: It appears that the development version of libcurl is not available. Please install the libcurl3-dev package.
</p>

<p>
第二项”是否选择Google云平台的支持”选择y之后出现了一个错误，需要libcurl，用apt-get安装，当然，基于国内的网络现状，这一项也可以选择no:
<code>sudo apt install libcurl3 libcurl3-dev</code>
</p>
</div>
</li>
<li>
<a id="sec-2-5-4-4" name="sec-2-5-4-4"></a>安装完毕之后重新执行<br><div class="outline-text-5" id="text-2-5-4-4">
<p>
<code>./configure</code>
</p>

<p>
除了两处选择yes or no 的地方外，还要注意 compute capability ，其他地方一路回车:
</p>

<pre class="example">
Please specify the location of python. [Default is /usr/bin/python]:
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] y
Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with GPU support? [y/N] y
GPU support will be enabled for TensorFlow
Please specify which gcc nvcc should use as the host compiler. [Default is /usr/bin/gcc]:
Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]:
Please specify the location where CUDA toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:
Please specify the Cudnn version you want to use. [Leave empty to use system default]:
Please specify the location where cuDNN library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: “3.5,5.2”]:
Setting up Cuda include
Setting up Cuda lib64
Setting up Cuda bin
Setting up Cuda nvvm
Setting up CUPTI include
Setting up CUPTI lib64
Configuration finished
</pre>
</div>
</li>
<li>
<a id="sec-2-5-4-5" name="sec-2-5-4-5"></a>第一个BUG：修改 CROSSTOOLS file to see this CUDA includes:<br><div class="outline-text-5" id="text-2-5-4-5">
<p>
You need to update the CROSSTOOLS file to see this CUDA includes:
</p>

<p>
<code>tensorflow/third_party/gpus/crosstool/CROSSTOOL</code>
</p>

<p>
Around line 65, add:
</p>

<pre class="example">
cxx_builtin_include_directory: "/usr/local/cuda-8.0/include"
</pre>
</div>

<ul class="org-ul"><li>
<a id="sec-2-5-4-5-1" name="sec-2-5-4-5-1"></a>是为了解决这个BUG<br><div class="outline-text-6" id="text-2-5-4-5-1">
<pre class="example">
ERROR: /home/zhaoji/TensorFlowDownload/tensorflow/tensorflow/core/kernels/BUILD:1518:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:depth_space_ops_gpu':
this rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/depthtospace_op_gpu.cu.cc':
  '/usr/local/cuda-8.0/include/cuda_runtime.h'
  '/usr/local/cuda-8.0/include/host_config.h'
  '/usr/local/cuda-8.0/include/builtin_types.h'
  '/usr/local/cuda-8.0/include/device_types.h'
  '/usr/local/cuda-8.0/include/host_defines.h'
  '/usr/local/cuda-8.0/include/driver_types.h'
  '/usr/local/cuda-8.0/include/surface_types.h'
  '/usr/local/cuda-8.0/include/texture_types.h'
  '/usr/local/cuda-8.0/include/vector_types.h'
  '/usr/local/cuda-8.0/include/library_types.h'
  '/usr/local/cuda-8.0/include/channel_descriptor.h'
  '/usr/local/cuda-8.0/include/cuda_runtime_api.h'
  '/usr/local/cuda-8.0/include/cuda_device_runtime_api.h'
  '/usr/local/cuda-8.0/include/driver_functions.h'
  '/usr/local/cuda-8.0/include/vector_functions.h'
  '/usr/local/cuda-8.0/include/vector_functions.hpp'
  '/usr/local/cuda-8.0/include/common_functions.h'
  '/usr/local/cuda-8.0/include/math_functions.h'
  '/usr/local/cuda-8.0/include/math_functions.hpp'
  '/usr/local/cuda-8.0/include/math_functions_dbl_ptx3.h'
  '/usr/local/cuda-8.0/include/math_functions_dbl_ptx3.hpp'
  '/usr/local/cuda-8.0/include/cuda_surface_types.h'
  '/usr/local/cuda-8.0/include/cuda_texture_types.h'
  '/usr/local/cuda-8.0/include/device_functions.h'
  '/usr/local/cuda-8.0/include/device_functions.hpp'
  '/usr/local/cuda-8.0/include/device_atomic_functions.h'
  '/usr/local/cuda-8.0/include/device_atomic_functions.hpp'
  '/usr/local/cuda-8.0/include/device_double_functions.h'
  '/usr/local/cuda-8.0/include/device_double_functions.hpp'
  '/usr/local/cuda-8.0/include/sm_20_atomic_functions.h'
  '/usr/local/cuda-8.0/include/sm_20_atomic_functions.hpp'
  '/usr/local/cuda-8.0/include/sm_32_atomic_functions.h'
  '/usr/local/cuda-8.0/include/sm_32_atomic_functions.hpp'
  '/usr/local/cuda-8.0/include/sm_35_atomic_functions.h'
  '/usr/local/cuda-8.0/include/sm_60_atomic_functions.h'
  '/usr/local/cuda-8.0/include/sm_60_atomic_functions.hpp'
  '/usr/local/cuda-8.0/include/sm_20_intrinsics.h'
  '/usr/local/cuda-8.0/include/sm_20_intrinsics.hpp'
  '/usr/local/cuda-8.0/include/sm_30_intrinsics.h'
  '/usr/local/cuda-8.0/include/sm_30_intrinsics.hpp'
  '/usr/local/cuda-8.0/include/sm_32_intrinsics.h'
  '/usr/local/cuda-8.0/include/sm_32_intrinsics.hpp'
  '/usr/local/cuda-8.0/include/sm_35_intrinsics.h'
  '/usr/local/cuda-8.0/include/surface_functions.h'
  '/usr/local/cuda-8.0/include/texture_fetch_functions.h'
  '/usr/local/cuda-8.0/include/texture_indirect_functions.h'
  '/usr/local/cuda-8.0/include/surface_indirect_functions.h'
  '/usr/local/cuda-8.0/include/device_launch_parameters.h'
  '/usr/local/cuda-8.0/include/cuda_fp16.h'
  '/usr/local/cuda-8.0/include/math_constants.h'
  '/usr/local/cuda-8.0/include/curand_kernel.h'
  '/usr/local/cuda-8.0/include/curand.h'
  '/usr/local/cuda-8.0/include/curand_discrete.h'
  '/usr/local/cuda-8.0/include/curand_precalc.h'
  '/usr/local/cuda-8.0/include/curand_mrg32k3a.h'
  '/usr/local/cuda-8.0/include/curand_mtgp32_kernel.h'
  '/usr/local/cuda-8.0/include/cuda.h'
  '/usr/local/cuda-8.0/include/curand_mtgp32.h'
  '/usr/local/cuda-8.0/include/curand_philox4x32_x.h'
  '/usr/local/cuda-8.0/include/curand_globals.h'
  '/usr/local/cuda-8.0/include/curand_uniform.h'
  '/usr/local/cuda-8.0/include/curand_normal.h'
  '/usr/local/cuda-8.0/include/curand_normal_static.h'
  '/usr/local/cuda-8.0/include/curand_lognormal.h'
  '/usr/local/cuda-8.0/include/curand_poisson.h'
  '/usr/local/cuda-8.0/include/curand_discrete2.h'.
nvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.
nvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.
Target //tensorflow/cc:tutorials_example_trainer failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 294.420s, Critical Path: 248.50s
</pre>
</div>
</li></ul>
</li>

<li>
<a id="sec-2-5-4-6" name="sec-2-5-4-6"></a>第二个BUG : zlib not installed<br><div class="outline-text-5" id="text-2-5-4-6">
<p>
configure: error: zlib not installed
Target //tensorflow/cc:tutorials<sub>example</sub><sub>trainer</sub> failed to build
</p>

<p>
google了一下，需要安装zlib1g-dev:
<code>sudo apt-get install zlib1g-dev</code>
</p>
</div>
</li>

<li>
<a id="sec-2-5-4-7" name="sec-2-5-4-7"></a>通过Bazel进行编译安装<br><div class="outline-text-5" id="text-2-5-4-7">
<div class="highlight"><pre><span></span># To build with GPU support:
$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package

$ bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg

# The name of the .whl file will depend on your platform.
$ sudo pip install /tmp/tensorflow_pkg/tensorflow-0.10.0-py2-none-any.whl
</pre></div>

<p>
需要等待一段时间
</p>

<p>
编译TensorFlow成功结束的时候，提示如下：
</p>

<pre class="example">
Target //tensorflow/cc:tutorials_example_trainer up-to-date:
bazel-bin/tensorflow/cc/tutorials_example_trainer
INFO: Elapsed time: 897.845s, Critical Path: 533.72s
</pre>
</div>
</li>
<li>
<a id="sec-2-5-4-8" name="sec-2-5-4-8"></a>执行一下TensorFlow官方文档里的例子，看看能否成功调用GTX 1080：<br><div class="outline-text-5" id="text-2-5-4-8">
<p>
<code>bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu</code>
</p>

<pre class="example">
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.835
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.65GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0: Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)
000003/000006 lambda = 1.841570 x = [0.669396 0.742906] y = [3.493999 -0.669396]
000006/000007 lambda = 1.841570 x = [0.669396 0.742906] y = [3.493999 -0.669396]
000009/000006 lambda = 1.841570 x = [0.669396 0.742906] y = [3.493999 -0.669396]
000009/000004 lambda = 1.841570 x = [0.669396 0.742906] y = [3.493999 -0.669396]
000000/000005 lambda = 1.841570 x = [0.669396 0.742906] y = [3.493999 -0.669396]
000000/000004 lambda = 1.841570 x = [0.669396 0.742906] y = [3.493999 -0.669396]
……
</pre>
<p>
没有问题，说明这种通过源代码编译TensorFlow使其支持GPU的方式已经成功了。
</p>
</div>
</li>
<li>
<a id="sec-2-5-4-9" name="sec-2-5-4-9"></a>python 中调用<br><div class="outline-text-5" id="text-2-5-4-9">
<p>
再在Python中调用一下TensorFlow:
import tensorflow as tf
</p>

<p>
提示错误：
</p>

<p>
ImportError: cannot import name pywrap<sub>tensorflow</sub></p>

<p>
虽然我们通过源代码安装编译的TensorFlow可用，但是Python版本并没有ready，所以继续：
</p>

<div class="highlight"><pre><span></span>bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
sudo pip install /tmp/tensorflow_pkg/tensorflow-0.9.0-py2-none-any.whl
</pre></div>

<p>
<code>sudo env "PATH=$PATH" pip install bulabula</code>
</p>

<p>
Requirement already satisfied (use –upgrade to upgrade): setuptools in /usr/lib/python2.7/dist-packages (from protobuf==3.0.0b2-&gt;tensorflow==0.9.0)
Installing collected packages: six, funcsigs, pbr, mock, protobuf, tensorflow
Successfully installed funcsigs-1.0.2 mock-2.0.0 pbr-1.10.0 protobuf-3.0.0b2 six-1.10.0 tensorflow-0.9.0
</p>

<p>
我们再次打开ipython，试一下tensorflow官方样例:
</p>
<div class="highlight"><pre><span></span><span class="n">Python</span> <span class="mf">2.7</span><span class="o">.</span><span class="mi">12</span> <span class="p">(</span><span class="n">default</span><span class="p">,</span> <span class="n">Jul</span>  <span class="mi">1</span> <span class="mi">2016</span><span class="p">,</span> <span class="mi">15</span><span class="p">:</span><span class="mi">12</span><span class="p">:</span><span class="mi">24</span><span class="p">)</span>
<span class="n">Type</span> <span class="s2">"copyright"</span><span class="p">,</span> <span class="s2">"credits"</span> <span class="ow">or</span> <span class="s2">"license"</span> <span class="k">for</span> <span class="n">more</span> <span class="n">information</span><span class="o">.</span>

<span class="n">IPython</span> <span class="mf">2.4</span><span class="o">.</span><span class="mi">1</span> <span class="o">--</span> <span class="n">An</span> <span class="n">enhanced</span> <span class="n">Interactive</span> <span class="n">Python</span><span class="o">.</span>
<span class="err">?</span>         <span class="o">-&gt;</span> <span class="n">Introduction</span> <span class="ow">and</span> <span class="n">overview</span> <span class="n">of</span> <span class="n">IPython</span><span class="s1">'s features.</span>
<span class="o">%</span><span class="n">quickref</span> <span class="o">-&gt;</span> <span class="n">Quick</span> <span class="n">reference</span><span class="o">.</span>
<span class="n">help</span>      <span class="o">-&gt;</span> <span class="n">Python</span><span class="s1">'s own help system.</span>
<span class="nb">object</span><span class="err">?</span>   <span class="o">-&gt;</span> <span class="n">Details</span> <span class="n">about</span> <span class="s1">'object'</span><span class="p">,</span> <span class="n">use</span> <span class="s1">'object??'</span> <span class="k">for</span> <span class="n">extra</span> <span class="n">details</span><span class="o">.</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="n">I</span> <span class="n">tensorflow</span><span class="o">/</span><span class="n">stream_executor</span><span class="o">/</span><span class="n">dso_loader</span><span class="o">.</span><span class="n">cc</span><span class="p">:</span><span class="mi">108</span> <span class="n">successfully</span> <span class="n">opened</span> <span class="n">CUDA</span> <span class="n">library</span> <span class="n">libcublas</span><span class="o">.</span><span class="n">so</span> <span class="n">locally</span>
<span class="n">I</span> <span class="n">tensorflow</span><span class="o">/</span><span class="n">stream_executor</span><span class="o">/</span><span class="n">dso_loader</span><span class="o">.</span><span class="n">cc</span><span class="p">:</span><span class="mi">108</span> <span class="n">successfully</span> <span class="n">opened</span> <span class="n">CUDA</span> <span class="n">library</span> <span class="n">libcudnn</span><span class="o">.</span><span class="n">so</span> <span class="n">locally</span>
<span class="n">I</span> <span class="n">tensorflow</span><span class="o">/</span><span class="n">stream_executor</span><span class="o">/</span><span class="n">dso_loader</span><span class="o">.</span><span class="n">cc</span><span class="p">:</span><span class="mi">108</span> <span class="n">successfully</span> <span class="n">opened</span> <span class="n">CUDA</span> <span class="n">library</span> <span class="n">libcufft</span><span class="o">.</span><span class="n">so</span> <span class="n">locally</span>
<span class="n">I</span> <span class="n">tensorflow</span><span class="o">/</span><span class="n">stream_executor</span><span class="o">/</span><span class="n">dso_loader</span><span class="o">.</span><span class="n">cc</span><span class="p">:</span><span class="mi">108</span> <span class="n">successfully</span> <span class="n">opened</span> <span class="n">CUDA</span> <span class="n">library</span> <span class="n">libcuda</span><span class="o">.</span><span class="n">so</span><span class="o">.</span><span class="mi">1</span> <span class="n">locally</span>
<span class="n">I</span> <span class="n">tensorflow</span><span class="o">/</span><span class="n">stream_executor</span><span class="o">/</span><span class="n">dso_loader</span><span class="o">.</span><span class="n">cc</span><span class="p">:</span><span class="mi">108</span> <span class="n">successfully</span> <span class="n">opened</span> <span class="n">CUDA</span> <span class="n">library</span> <span class="n">libcurand</span><span class="o">.</span><span class="n">so</span> <span class="n">locally</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">3</span><span class="p">]:</span> <span class="n">x_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">4</span><span class="p">]:</span> <span class="n">y_data</span> <span class="o">=</span> <span class="n">x_data</span> <span class="o">*</span> <span class="mf">0.1</span> <span class="o">+</span> <span class="mf">0.3</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">5</span><span class="p">]:</span> <span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">6</span><span class="p">]:</span> <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">]))</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">7</span><span class="p">]:</span> <span class="n">y</span> <span class="o">=</span> <span class="n">W</span> <span class="o">*</span> <span class="n">x_data</span> <span class="o">+</span> <span class="n">b</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">8</span><span class="p">]:</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_data</span><span class="p">))</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">9</span><span class="p">]:</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">10</span><span class="p">]:</span> <span class="n">train</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">11</span><span class="p">]:</span> <span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">initialize_all_variables</span><span class="p">()</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">12</span><span class="p">]:</span> <span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="n">I</span> <span class="n">tensorflow</span><span class="o">/</span><span class="n">core</span><span class="o">/</span><span class="n">common_runtime</span><span class="o">/</span><span class="n">gpu</span><span class="o">/</span><span class="n">gpu_init</span><span class="o">.</span><span class="n">cc</span><span class="p">:</span><span class="mi">102</span><span class="p">]</span> <span class="n">Found</span> <span class="n">device</span> <span class="mi">0</span> <span class="k">with</span> <span class="n">properties</span><span class="p">:</span>
<span class="n">name</span><span class="p">:</span> <span class="n">GeForce</span> <span class="n">GTX</span> <span class="mi">1080</span>
<span class="n">major</span><span class="p">:</span> <span class="mi">6</span> <span class="n">minor</span><span class="p">:</span> <span class="mi">1</span> <span class="n">memoryClockRate</span> <span class="p">(</span><span class="n">GHz</span><span class="p">)</span> <span class="mf">1.835</span>
<span class="n">pciBusID</span> <span class="mo">0000</span><span class="p">:</span><span class="mo">01</span><span class="p">:</span><span class="mf">00.0</span>
<span class="n">Total</span> <span class="n">memory</span><span class="p">:</span> <span class="mf">7.92</span><span class="n">GiB</span>
<span class="n">Free</span> <span class="n">memory</span><span class="p">:</span> <span class="mf">7.65</span><span class="n">GiB</span>
<span class="n">I</span> <span class="n">tensorflow</span><span class="o">/</span><span class="n">core</span><span class="o">/</span><span class="n">common_runtime</span><span class="o">/</span><span class="n">gpu</span><span class="o">/</span><span class="n">gpu_init</span><span class="o">.</span><span class="n">cc</span><span class="p">:</span><span class="mi">126</span><span class="p">]</span> <span class="n">DMA</span><span class="p">:</span> <span class="mi">0</span>
<span class="n">I</span> <span class="n">tensorflow</span><span class="o">/</span><span class="n">core</span><span class="o">/</span><span class="n">common_runtime</span><span class="o">/</span><span class="n">gpu</span><span class="o">/</span><span class="n">gpu_init</span><span class="o">.</span><span class="n">cc</span><span class="p">:</span><span class="mi">136</span><span class="p">]</span> <span class="mi">0</span><span class="p">:</span>   <span class="n">Y</span>
<span class="n">I</span> <span class="n">tensorflow</span><span class="o">/</span><span class="n">core</span><span class="o">/</span><span class="n">common_runtime</span><span class="o">/</span><span class="n">gpu</span><span class="o">/</span><span class="n">gpu_device</span><span class="o">.</span><span class="n">cc</span><span class="p">:</span><span class="mi">838</span><span class="p">]</span> <span class="n">Creating</span> <span class="n">TensorFlow</span> <span class="n">device</span> <span class="p">(</span><span class="o">/</span><span class="n">gpu</span><span class="p">:</span><span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">device</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n">GeForce</span> <span class="n">GTX</span> <span class="mi">1080</span><span class="p">,</span> <span class="n">pci</span> <span class="n">bus</span> <span class="nb">id</span><span class="p">:</span> <span class="mo">0000</span><span class="p">:</span><span class="mo">01</span><span class="p">:</span><span class="mf">00.0</span><span class="p">)</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">13</span><span class="p">]:</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">14</span><span class="p">]:</span> <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">201</span><span class="p">):</span>
   <span class="o">....</span><span class="p">:</span>     <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
   <span class="o">....</span><span class="p">:</span>     <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
   <span class="o">....</span><span class="p">:</span>         <span class="k">print</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">W</span><span class="p">),</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>
   <span class="o">....</span><span class="p">:</span>        
<span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">0.10331395</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.62236434</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">))</span>
<span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.03067014</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.3403711</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">))</span>
<span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.08353967</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.30958495</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">))</span>
<span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.09609199</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.30227566</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">))</span>
<span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.09907217</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.3005403</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">))</span>
<span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.09977971</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.30012828</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">))</span>
<span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.0999477</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.30003047</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">))</span>
<span class="p">(</span><span class="mi">140</span><span class="p">,</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.0999876</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.30000722</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">))</span>
<span class="p">(</span><span class="mi">160</span><span class="p">,</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.09999706</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.30000171</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">))</span>
<span class="p">(</span><span class="mi">180</span><span class="p">,</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.09999929</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.30000043</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">))</span>
<span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.09999985</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span> <span class="n">array</span><span class="p">([</span> <span class="mf">0.3000001</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">))</span>
</pre></div>

<p>
终于OK了，之后就可以尽情享用基于GTX 1080 GPU版的TensorFlow了。
</p>

<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">x_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">y_data</span> <span class="o">=</span> <span class="n">x_data</span> <span class="o">*</span> <span class="mf">0.1</span> <span class="o">+</span> <span class="mf">0.3</span>

<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>

<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">]))</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">W</span> <span class="o">*</span> <span class="n">x_data</span> <span class="o">+</span> <span class="n">b</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_data</span><span class="p">))</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

<span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">initialize_all_variables</span><span class="p">()</span>

<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>

<span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">201</span><span class="p">):</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
	<span class="k">print</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">W</span><span class="p">),</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>
</pre></div>
</div>
</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3">修补图像</h2>
<div class="outline-text-2" id="text-3">
<p>
<a href="http://bamos.github.io/2016/08/09/deep-completion/">http://bamos.github.io/2016/08/09/deep-completion/</a>
</p>

<div class="highlight"><pre><span></span># 生成一个工作空间
cd git/
mkdir tensorflow
cd tensorflow
## git 下来 
# git clone https://github.com/cmusatyalab/openface.git
# cd openface
# pip2 install -r requirements.txt
# python2 setup.py install
# cd .. 

git clone https://github.com/bamos/dcgan-completion.tensorflow.git
</pre></div>
<p>
git 不好用，还是看下面的这个吧<a href="zai-geforce-1080-shang-da-jian-tensorflow-gpu-ban-ben.html#sec-3-1">OpenFace Docker</a> 
</p>


<p>
Next download a dataset of face images. It doesn’t matter if they have labels or not, we’ll get rid of them. A non-exhaustive list of options are: MS-Celeb-1M, CelebA, CASIA-WebFace, FaceScrub, LFW, and MegaFace. Place the dataset in dcgan-completion.tensorflow/data/your-dataset/raw to indicate it’s the dataset’s raw images.
</p>

<p>
Now we’ll use OpenFace’s alignment tool to pre-process the images to be 64x64.
</p>


<div class="highlight"><pre><span></span># -v 参数是加载文件夹用的
sudo docker run -p 9000:9000 -p 8000:8000 -t -v /home/zhaoji/git/tensorflow/dcgan-completion.tensorflow/data/LFW:/LFW -i bamos/openface /bin/bash

/root/openface/util/align-dlib.py /LFW/raw align innerEyesAndBottomLip /LFW/aligned --size 64
</pre></div>

<p>
And finally we’ll flatten the aligned images directory so that it just contains images and no sub-directories.
</p>

<div class="highlight"><pre><span></span>cd LFW/aligned
find . -name '*.png' -exec mv {} . \;
find . -type d -empty -delete
cd ../
</pre></div>

<p>
We’re ready to train the DCGAN. After installing TensorFlow, start the training.
</p>

<div class="highlight"><pre><span></span>./train-dcgan.py --dataset ./data/your-dataset/aligned --epoch 20
</pre></div>
<p>
You can check what randomly sampled images from the generator look like in the samples directory. I’m training on the CASIA-WebFace and FaceScrub datasets because I had them on hand. After 14 epochs, the samples from mine look like:
</p>
</div>
<div id="outline-container-sec-3-1" class="outline-3">
<h3 id="sec-3-1">OpenFace Docker</h3>
<div class="outline-text-3" id="text-3-1">
<p>
The quickest way to getting started is to use our pre-built automated Docker build, which is available from bamos/openface. This does not require or use a locally checked out copy of OpenFace. To use on your images, share a directory between your host and the Docker container.
</p>

<div class="highlight"><pre><span></span>sudo docker pull bamos/openface
sudo docker run -p 9000:9000 -p 8000:8000 -t -i bamos/openface /bin/bash
cd /root/openface
./demos/compare.py images/examples/{lennon*,clapton*}
./demos/classifier.py infer models/openface/celeb-classifier.nn4.small2.v1.pkl ./images/examples/carell.jpg
./demos/web/start-servers.sh
</pre></div>
</div>
</div>
</div>
<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4">基本知识</h2>
<div class="outline-text-2" id="text-4">
<p>
使用图 (graph) 来表示计算任务.
在被称之为 会话 (Session) 的上下文 (context) 中执行图.
使用 tensor 表示数据.
通过 变量 (Variable) 维护状态.
使用 feed 和 fetch 可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据.
</p>
</div>
<div id="outline-container-sec-4-1" class="outline-3">
<h3 id="sec-4-1">变量与运算 Variables and ops</h3>
</div>
<div id="outline-container-sec-4-2" class="outline-3">
<h3 id="sec-4-2">两种作用域：变量作用域 variable<sub>scope</sub> 与命名作用域 name<sub>scope</sub>
</h3>
<div class="outline-text-3" id="text-4-2">
</div>
<div id="outline-container-sec-4-2-1" class="outline-4">
<h4 id="sec-4-2-1">变量作用域目标是为了影响变量 variable ，对于其它的运算 op 同样也会影响</h4>
<div class="outline-text-4" id="text-4-2-1">
<p>
with tf.variable<sub>scope</sub>("name"), this implicitly opens a tf.name<sub>scope</sub>("name").
</p>

<div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">"foo"</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s2">"v"</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">"foo/add"</span>
</pre></div>
</div>
</div>
<div id="outline-container-sec-4-2-2" class="outline-4">
<h4 id="sec-4-2-2">而 name<sub>scope</sub> 不一定改变 Variable 的名字</h4>
<div class="outline-text-4" id="text-4-2-2">
<ul class="org-ul">
<li>用 tf.Variable 创建 variable 前面会加上 name<sub>scope</sub> 也就是所有的scope
</li>
<li>用 tf.get<sub>variable</sub> 创建 variable 前面只会加上 variable<sub>scope</sub>
</li>
</ul>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">"foo"</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">"bar"</span><span class="p">):</span>
	<span class="n">v</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s2">"v"</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span>
	<span class="n">v1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">]),</span> <span class="n">name</span> <span class="o">=</span> <span class="s2">"v1"</span><span class="p">)</span>
	<span class="n">x</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">+</span> <span class="n">v</span>
<span class="k">print</span><span class="p">(</span><span class="s2">"v  ="</span><span class="p">,</span><span class="n">v</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">"v1 ="</span><span class="p">,</span><span class="n">v1</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">"op ="</span><span class="p">,</span><span class="n">x</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="c1"># assert v.name == "foo/v:0"</span>
<span class="c1"># assert x.op.name == "foo/bar/add"</span>
</pre></div>
</div>
</div>
<div id="outline-container-sec-4-2-3" class="outline-4">
<h4 id="sec-4-2-3">两者的核心区别： tf.get<sub>variable，</sub> 用于共享变量</h4>
<div class="outline-text-4" id="text-4-2-3">
<p>
使用 tf.get<sub>variable</sub> 创建变量时，会在 variable<sub>scope</sub> 中寻找，reuse 的范围是可以
大于 name<sub>scope</sub> 的，当然重名的范围也是这么大
</p>

<ul class="org-ul">
<li>tf.name<sub>scope</sub> just add a prefix to all tensor created in that scope (except the vars created with tf.get<sub>variable</sub>)
</li>
<li>tf.variable<sub>scope</sub> add a prefix to the variables created with tf.get<sub>variable</sub>.
</li>
</ul>
<p>
这么设计的好处 
</p>
<ul class="org-ul">
<li>一般情况下，你不会想要共享变量，如果想要共享，你要用 tf.get<sub>variable</sub> 来创建变
量，并用 tf.variable<sub>scope</sub> 来控制它的作用域，这个作用域可以跨 name<sub>scope</sub>
</li>
<li>If it were possible to use tf.name<sub>scope</sub> in this case, maybe this would
decrease the code readability.
</li>
</ul>
<p>
重名机制的体现
</p>
<ul class="org-ul">
<li>用 tf.get<sub>variable</sub> 而不是 tf.Variable 来创建变量时， Tensorflow will start
checking the names of the vars created with the same method to see if they
collide. 有重名的会报异常，
</li>
<li>这个时候改变 tf.name<sub>scope</sub> 来避免用 tf.get<sub>variable</sub> 创建的变量重名，是没用的，仍然会报异常.
</li>
<li>Only tf.variable<sub>scope</sub> context manager will effectively change the name of
your var in this case.
</li>
<li>Or if you want to reuse the variable you should call
scope.reuse<sub>variables</sub>() before creating the var the second time.
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-4-2-4" class="outline-4">
<h4 id="sec-4-2-4">切换方法</h4>
<div class="outline-text-4" id="text-4-2-4">
<ul class="org-ul">
<li>用字符串是叠加
</li>

<li>用 object （表现为变量名）是跳转
</li>

<li>When opening a variable scope using a captured object instead of a string, we
do not alter the current name scope for ops.
</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-sec-5" class="outline-2">
<h2 id="sec-5">版本</h2>
<div class="outline-text-2" id="text-5">
</div>
<div id="outline-container-sec-5-1" class="outline-3">
<h3 id="sec-5-1">Batch Norm 巨慢</h3>
<div class="outline-text-3" id="text-5-1">
<p>
解决方法 升级到 0.10 正式版
</p>

<p>
<a href="https://github.com/tensorflow/tensorflow/issues/1502">https://github.com/tensorflow/tensorflow/issues/1502</a>
</p>

<p>
If I recall correctly, the 0.10 release candidate binary had a performance regression in some of the reduction kernels (on certain GPUs). I believe this is fixed now at HEAD, and will be in the actual release which is due any day now.
</p>

<p>
Can you try with the nightly build and confirm whether this is still a problem?
</p>

<p>
0.10.0rc0 has some known performance regressions which should be fixed by the actual release.
</p>

<p>
安装中的BUG——解决方案，升级Bazel
</p>

<p>
expected ConfigurationTransition or NoneType for 'cfg' while calling label<sub>list</sub> but got string instead:     data.
</p>

<p>
<a href="https://github.com/tensorflow/tensorflow/issues/4531">https://github.com/tensorflow/tensorflow/issues/4531</a>
</p>
</div>
</div>
</div>
    </div>
    <aside class="postpromonav"><nav><ul class="pager hidden-print">
<li class="previous">
                <a href="cong-xue-sheng-dao-zhi-chang.html" rel="prev" title="从学生到职场">前一篇</a>
            </li>
            <li class="next">
                <a href="git-shi-yong-ji-qiao.html" rel="next" title="git 使用技巧">后一篇</a>
            </li>
        </ul></nav></aside></article>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2016         <a href="mailto:qiwulun08@gmail.com">Zhao JI</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
        </footer>
</div>
</div>


            <script src="../assets/js/all-nocdn.js"></script><script src="../assets/js/colorbox-i18n/jquery.colorbox-zh-CN.js"></script><script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script><!-- fancy dates --><script>
    moment.locale("zh-cn");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates -->
</body>
</html>
